{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atul/.local/lib/python3.8/site-packages/sklearn/datasets/_openml.py:1022: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Grid Search Best Parameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200}\n",
      "Grid Search MSE on test set: 5.868017593238944\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Random Search Best Parameters: {'n_estimators': 700, 'max_depth': 3, 'learning_rate': 0.095}\n",
      "Random Search MSE on test set: 5.760615621800232\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# Load data\n",
    "data = fetch_openml(name='boston', version=1, as_frame=True)\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define parameter grid for GridSearchCV\n",
    "param_grid_gridsearch = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'n_estimators': [100, 200, 300]\n",
    "}\n",
    "\n",
    "# Define parameter grid for RandomizedSearchCV\n",
    "param_dist_randomsearch = {\n",
    "    'max_depth': [3, 5, 7, 9, 11, 13, 15],\n",
    "    'learning_rate': np.linspace(0.001, 0.1, 100),\n",
    "    'n_estimators': np.arange(100, 1000, 100)\n",
    "}\n",
    "\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=XGBRegressor(random_state=42, enable_categorical=True),\n",
    "                           param_grid=param_grid_gridsearch,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           cv=5,\n",
    "                           verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Grid Search Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "best_grid_model = grid_search.best_estimator_\n",
    "y_pred_grid = best_grid_model.predict(X_test)\n",
    "mse_grid = mean_squared_error(y_test, y_pred_grid)\n",
    "print(\"Grid Search MSE on test set:\", mse_grid)\n",
    "\n",
    "# Perform RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=XGBRegressor(random_state=42, enable_categorical=True),\n",
    "                                   param_distributions=param_dist_randomsearch,\n",
    "                                   n_iter=100,\n",
    "                                   scoring='neg_mean_squared_error',\n",
    "                                   cv=5,\n",
    "                                   verbose=1,\n",
    "                                   random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "print(\"Random Search Best Parameters:\", random_search.best_params_)\n",
    "best_random_model = random_search.best_estimator_\n",
    "y_pred_random = best_random_model.predict(X_test)\n",
    "mse_random = mean_squared_error(y_test, y_pred_random)\n",
    "print(\"Random Search MSE on test set:\", mse_random)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:07<00:00,  1.49trial/s, best loss: 5.174801631248915]\n",
      "Hyperopt Best Parameters: {'learning_rate': 0.08393931195869206, 'max_depth': 3, 'n_estimators': 500}\n",
      "Hyperopt MSE on test set: 5.174801631248915\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp, tpe, fmin, Trials\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "\n",
    "# Define search space for Hyperopt\n",
    "param_space_hyperopt = {\n",
    "    'max_depth': hp.choice('max_depth', np.arange(3, 16, dtype=int)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.001), np.log(0.1)),\n",
    "    'n_estimators': hp.choice('n_estimators', np.arange(100, 1000, 100, dtype=int))\n",
    "}\n",
    "\n",
    "# Define objective function for Hyperopt\n",
    "def objective(params):\n",
    "    model = XGBRegressor(**params, random_state=42, enable_categorical=True)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    return mse\n",
    "\n",
    "\n",
    "# Perform Hyperopt\n",
    "trials = Trials()\n",
    "best_hyperopt = fmin(fn=objective,\n",
    "                     space=param_space_hyperopt,\n",
    "                     algo=tpe.suggest,\n",
    "                     max_evals=100,\n",
    "                     trials=trials,\n",
    "                     rstate=np.random.default_rng(42),\n",
    "                     return_argmin=False\n",
    "                     )\n",
    "print(\"Hyperopt Best Parameters:\", best_hyperopt)\n",
    "\n",
    "best_hyperopt_model = XGBRegressor(**best_hyperopt, random_state=42, enable_categorical=True)\n",
    "best_hyperopt_model.fit(X_train, y_train)\n",
    "y_pred_hyperopt = best_hyperopt_model.predict(X_test)\n",
    "mse_hyperopt = mean_squared_error(y_test, y_pred_hyperopt)\n",
    "print(\"Hyperopt MSE on test set:\", mse_hyperopt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
