{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import numpy as np\n",
    "import math\n",
    "from utils import divide_on_feature, train_test_split, standardize, mean_squared_error, get_random_subsets\n",
    "from utils import calculate_entropy, accuracy_score, calculate_variance, Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DecisionNode():\n",
    "    \"\"\"Class that represents a decision node or leaf in the decision tree\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    feature_i: int\n",
    "        Feature index which we want to use as the threshold measure.\n",
    "    threshold: float\n",
    "        The value that we will compare feature values at feature_i against to\n",
    "        determine the prediction.\n",
    "    value: float\n",
    "        The class prediction if classification tree, or float value if regression tree.\n",
    "    true_branch: DecisionNode\n",
    "        Next decision node for samples where features value met the threshold.\n",
    "    false_branch: DecisionNode\n",
    "        Next decision node for samples where features value did not meet the threshold.\n",
    "    \"\"\"\n",
    "    def __init__(self, feature_i=None, threshold=None,\n",
    "                 value=None, true_branch=None, false_branch=None):\n",
    "        self.feature_i = feature_i          # Index for the feature that is tested\n",
    "        self.threshold = threshold          # Threshold value for feature\n",
    "        self.value = value                  # Value if the node is a leaf in the tree\n",
    "        self.true_branch = true_branch      # 'Left' subtree\n",
    "        self.false_branch = false_branch    # 'Right' subtree\n",
    "\n",
    "\n",
    "# Super class of RegressionTree and ClassificationTree\n",
    "class DecisionTree(object):\n",
    "    \"\"\"Super class of RegressionTree and ClassificationTree.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    min_samples_split: int\n",
    "        The minimum number of samples needed to make a split when building a tree.\n",
    "    min_impurity: float\n",
    "        The minimum impurity required to split the tree further.\n",
    "    max_depth: int\n",
    "        The maximum depth of a tree.\n",
    "    loss: function\n",
    "        Loss function that is used for Gradient Boosting models to calculate impurity.\n",
    "    \"\"\"\n",
    "    def __init__(self, min_samples_split=2, min_impurity=1e-7,\n",
    "                 max_depth=float(\"inf\"), loss=None):\n",
    "        self.root = None  # Root node in dec. tree\n",
    "        # Minimum n of samples to justify split\n",
    "        self.min_samples_split = min_samples_split\n",
    "        # The minimum impurity to justify split\n",
    "        self.min_impurity = min_impurity\n",
    "        # The maximum depth to grow the tree to\n",
    "        self.max_depth = max_depth\n",
    "        # Function to calculate impurity (classif.=>info gain, regr=>variance reduct.)\n",
    "        self._impurity_calculation = None\n",
    "        # Function to determine prediction of y at leaf\n",
    "        self._leaf_value_calculation = None\n",
    "        # If y is one-hot encoded (multi-dim) or not (one-dim)\n",
    "        self.one_dim = None\n",
    "        # If Gradient Boost\n",
    "        self.loss = loss\n",
    "\n",
    "    def fit(self, X, y, loss=None):\n",
    "        \"\"\" Build decision tree \"\"\"\n",
    "        self.one_dim = len(np.shape(y)) == 1\n",
    "        self.root = self._build_tree(X, y)\n",
    "        self.loss=None\n",
    "\n",
    "    def _build_tree(self, X, y, current_depth=0):\n",
    "        \"\"\" Recursive method which builds out the decision tree and splits X and respective y\n",
    "        on the feature of X which (based on impurity) best separates the data\"\"\"\n",
    "\n",
    "        largest_impurity = 0\n",
    "        best_criteria = None    # Feature index and threshold\n",
    "        best_sets = None        # Subsets of the data\n",
    "\n",
    "        # Check if expansion of y is needed\n",
    "        if len(np.shape(y)) == 1:\n",
    "            y = np.expand_dims(y, axis=1)\n",
    "\n",
    "        # Add y as last column of X\n",
    "        Xy = np.concatenate((X, y), axis=1)\n",
    "\n",
    "        n_samples, n_features = np.shape(X)\n",
    "\n",
    "        if n_samples >= self.min_samples_split and current_depth <= self.max_depth:\n",
    "            # Calculate the impurity for each feature\n",
    "            for feature_i in range(n_features):\n",
    "                # All values of feature_i\n",
    "                feature_values = np.expand_dims(X[:, feature_i], axis=1)\n",
    "                unique_values = np.unique(feature_values)\n",
    "\n",
    "                # Iterate through all unique values of feature column i and\n",
    "                # calculate the impurity\n",
    "                for threshold in unique_values:\n",
    "                    # Divide X and y depending on if the feature value of X at index feature_i\n",
    "                    # meets the threshold\n",
    "                    Xy1, Xy2 = divide_on_feature(Xy, feature_i, threshold)\n",
    "\n",
    "                    if len(Xy1) > 0 and len(Xy2) > 0:\n",
    "                        # Select the y-values of the two sets\n",
    "                        y1 = Xy1[:, n_features:]\n",
    "                        y2 = Xy2[:, n_features:]\n",
    "\n",
    "                        # Calculate impurity\n",
    "                        impurity = self._impurity_calculation(y, y1, y2)\n",
    "\n",
    "                        # If this threshold resulted in a higher information gain than previously\n",
    "                        # recorded save the threshold value and the feature\n",
    "                        # index\n",
    "                        if impurity > largest_impurity:\n",
    "                            largest_impurity = impurity\n",
    "                            best_criteria = {\"feature_i\": feature_i, \"threshold\": threshold}\n",
    "                            best_sets = {\n",
    "                                \"leftX\": Xy1[:, :n_features],   # X of left subtree\n",
    "                                \"lefty\": Xy1[:, n_features:],   # y of left subtree\n",
    "                                \"rightX\": Xy2[:, :n_features],  # X of right subtree\n",
    "                                \"righty\": Xy2[:, n_features:]   # y of right subtree\n",
    "                                }\n",
    "\n",
    "        if largest_impurity > self.min_impurity:\n",
    "            # Build subtrees for the right and left branches\n",
    "            true_branch = self._build_tree(best_sets[\"leftX\"], best_sets[\"lefty\"], current_depth + 1)\n",
    "            false_branch = self._build_tree(best_sets[\"rightX\"], best_sets[\"righty\"], current_depth + 1)\n",
    "            return DecisionNode(feature_i=best_criteria[\"feature_i\"], threshold=best_criteria[\n",
    "                                \"threshold\"], true_branch=true_branch, false_branch=false_branch)\n",
    "\n",
    "        # We're at leaf => determine value\n",
    "        leaf_value = self._leaf_value_calculation(y)\n",
    "\n",
    "        return DecisionNode(value=leaf_value)\n",
    "\n",
    "\n",
    "    def predict_value(self, x, tree=None):\n",
    "        \"\"\" Do a recursive search down the tree and make a prediction of the data sample by the\n",
    "            value of the leaf that we end up at \"\"\"\n",
    "\n",
    "        if tree is None:\n",
    "            tree = self.root\n",
    "\n",
    "        # If we have a value (i.e we're at a leaf) => return value as the prediction\n",
    "        if tree.value is not None:\n",
    "            return tree.value\n",
    "\n",
    "        # Choose the feature that we will test\n",
    "        feature_value = x[tree.feature_i]\n",
    "\n",
    "        # Determine if we will follow left or right branch\n",
    "        branch = tree.false_branch\n",
    "        if isinstance(feature_value, int) or isinstance(feature_value, float):\n",
    "            if feature_value >= tree.threshold:\n",
    "                branch = tree.true_branch\n",
    "        elif feature_value == tree.threshold:\n",
    "            branch = tree.true_branch\n",
    "\n",
    "        # Test subtree\n",
    "        return self.predict_value(x, branch)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\" Classify samples one by one and return the set of labels \"\"\"\n",
    "        y_pred = [self.predict_value(sample) for sample in X]\n",
    "        return y_pred\n",
    "\n",
    "    def print_tree(self, tree=None, indent=\" \"):\n",
    "        \"\"\" Recursively print the decision tree \"\"\"\n",
    "        if not tree:\n",
    "            tree = self.root\n",
    "\n",
    "        # If we're at leaf => print the label\n",
    "        if tree.value is not None:\n",
    "            print (tree.value)\n",
    "        # Go deeper down the tree\n",
    "        else:\n",
    "            # Print test\n",
    "            print (\"%s:%s? \" % (tree.feature_i, tree.threshold))\n",
    "            # Print the true scenario\n",
    "            print (\"%sT->\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.true_branch, indent + indent)\n",
    "            # Print the false scenario\n",
    "            print (\"%sF->\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.false_branch, indent + indent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationTree(DecisionTree):\n",
    "    def _calculate_information_gain(self, y, y1, y2):\n",
    "        # Calculate information gain\n",
    "        p = len(y1) / len(y)\n",
    "        entropy = calculate_entropy(y)\n",
    "        info_gain = entropy - p * \\\n",
    "            calculate_entropy(y1) - (1 - p) * \\\n",
    "            calculate_entropy(y2)\n",
    "\n",
    "        return info_gain\n",
    "\n",
    "    def _majority_vote(self, y):\n",
    "        most_common = None\n",
    "        max_count = 0\n",
    "        for label in np.unique(y):\n",
    "            # Count number of occurences of samples with label\n",
    "            count = len(y[y == label])\n",
    "            if count > max_count:\n",
    "                most_common = label\n",
    "                max_count = count\n",
    "        return most_common\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self._impurity_calculation = self._calculate_information_gain\n",
    "        self._leaf_value_calculation = self._majority_vote\n",
    "        super(ClassificationTree, self).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest():\n",
    "    \"\"\"Random Forest classifier. Uses a collection of classification trees that\n",
    "    trains on random subsets of the data using a random subsets of the features.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_estimators: int\n",
    "        The number of classification trees that are used.\n",
    "    max_features: int\n",
    "        The maximum number of features that the classification trees are allowed to\n",
    "        use.\n",
    "    min_samples_split: int\n",
    "        The minimum number of samples needed to make a split when building a tree.\n",
    "    min_gain: float\n",
    "        The minimum impurity required to split the tree further. \n",
    "    max_depth: int\n",
    "        The maximum depth of a tree.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_estimators=100, max_features=None, min_samples_split=2,\n",
    "                 min_gain=0, max_depth=float(\"inf\")):\n",
    "        self.n_estimators = n_estimators    # Number of trees\n",
    "        self.max_features = max_features    # Maxmimum number of features per tree\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_gain = min_gain            # Minimum information gain req. to continue\n",
    "        self.max_depth = max_depth          # Maximum depth for tree\n",
    "        self.progressbar = progressbar.ProgressBar(widgets=bar_widgets)\n",
    "\n",
    "        # Initialize decision trees\n",
    "        self.trees = []\n",
    "        for _ in range(n_estimators):\n",
    "            self.trees.append(\n",
    "                ClassificationTree(\n",
    "                    min_samples_split=self.min_samples_split,\n",
    "                    min_impurity=min_gain,\n",
    "                    max_depth=self.max_depth))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_features = np.shape(X)[1]\n",
    "        # If max_features have not been defined => select it as\n",
    "        # sqrt(n_features)\n",
    "        if not self.max_features:\n",
    "            self.max_features = int(math.sqrt(n_features))\n",
    "\n",
    "        # Choose one random subset of the data for each tree\n",
    "        subsets = get_random_subsets(X, y, self.n_estimators)\n",
    "\n",
    "        for i in self.progressbar(range(self.n_estimators)):\n",
    "            X_subset, y_subset = subsets[i]\n",
    "            # Feature bagging (select random subsets of the features)\n",
    "            idx = np.random.choice(range(n_features), size=self.max_features, replace=True)\n",
    "            # Save the indices of the features for prediction\n",
    "            self.trees[i].feature_indices = idx\n",
    "            # Choose the features corresponding to the indices\n",
    "            X_subset = X_subset[:, idx]\n",
    "            # Fit the tree to the data\n",
    "            self.trees[i].fit(X_subset, y_subset)\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_preds = np.empty((X.shape[0], len(self.trees)))\n",
    "        # Let each tree make a prediction on the data\n",
    "        for i, tree in enumerate(self.trees):\n",
    "            # Indices of the features that the tree has trained on\n",
    "            idx = tree.feature_indices\n",
    "            # Make a prediction based on those features\n",
    "            prediction = tree.predict(X[:, idx])\n",
    "            y_preds[:, i] = prediction\n",
    "            \n",
    "        y_pred = []\n",
    "        # For each sample\n",
    "        for sample_predictions in y_preds:\n",
    "            # Select the most common class prediction\n",
    "            y_pred.append(np.bincount(sample_predictions.astype('int')).argmax())\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100% [------------------------------------------------] Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import progressbar\n",
    "from utils import bar_widgets\n",
    "from utils import Plot\n",
    "\n",
    "\n",
    "data = datasets.load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, seed=0)\n",
    "\n",
    "clf = RandomForest(n_estimators=20)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print (\"Accuracy:\", accuracy)\n",
    "\n",
    "Plot().plot_in_2d(X_test, y_pred, title=\"Random Forest\", accuracy=accuracy, legend_labels=data.target_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
